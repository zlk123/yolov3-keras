{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "import struct\n",
    "\n",
    "\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers import LeakyReLU,AvgPool2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.merge import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "config = K.tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = K.tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "from tqdm import tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, cv2\n",
    "from preprocessing import parse_annotation, BatchGenerator\n",
    "from utils import WeightReader, decode_netout, draw_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ANCHORS  = [[0.36,0.17,  0.67,0.24, 0.18,0.105], [0.65,0.16, 0.197,0.06, 0.39,0.076],[0.18,0.02, 0.35,0.026, 0.56,0.03]]\n",
    "\n",
    "LABELS = ['tableRegion', 'figureRegion', 'formulaRegion']\n",
    "GRID_H,  GRID_W  = 15, 15\n",
    "IMAGE_H, IMAGE_W = GRID_H*64,  GRID_W*64\n",
    "\n",
    "\n",
    "ANCHORS = np.asarray(ANCHORS,dtype=np.float32)*np.asarray([[GRID_H], [GRID_H*2], [GRID_H*4]])\n",
    "BOX              = 3\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.6#0.5\n",
    "NMS_THRESHOLD    = 0.3#0.45\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 8\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_path = '../experimental/yolov3.weights'                      \n",
    "train_image_folder = '/home/zhuleike/data/science/Train/JPEGImages/'\n",
    "train_annot_folder = '/home/zhuleike/data/science/Train/Annotations/'\n",
    "test_image_folder = '/home/zhuleike/data/science/Test/JPEGImages/'\n",
    "test_annot_folder = '/home/zhuleike/data/science/Test/annotations/'\n",
    "#valid_annot_folder = '/home/trunk/RTrunk0/zhuleike/data/VOCdevkit/VOC2012/Annotations/valid/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        \n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "        \n",
    "        return self.label\n",
    "    \n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "            \n",
    "        return self.score\n",
    "\n",
    "def _conv_block(inp, convs, skip=True):\n",
    "    x = inp\n",
    "    count = 0\n",
    "    i = 0\n",
    "    for conv in convs:\n",
    "        if count == (len(convs) - 2) and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "        \n",
    "\n",
    "        x = Conv2D(conv['filter'], \n",
    "                   kernel_size = conv['kernel'], \n",
    "                   strides=conv['stride'], \n",
    "                   padding='same', \n",
    "                   name='conv_' + str(conv['layer_idx']), \n",
    "                   use_bias=False if conv['bnorm'] else True)(x)\n",
    "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "\n",
    "    return add([skip_connection, x]) if skip else x\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3          \n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    \n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    \n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union\n",
    "\n",
    "def make_yolov3_model():\n",
    "    input_image = Input(shape=(None, None, 3))\n",
    "\n",
    "    # Layer  0 => 4\n",
    "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "\n",
    "    # Layer  5 => 8\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "\n",
    "    # Layer  9 => 11\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "\n",
    "    # Layer 12 => 15\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "\n",
    "    # Layer 16 => 36\n",
    "    \n",
    "    for i in range(7):\n",
    "        if i % 2 == 0:\n",
    "            tempkernel = (5,1)\n",
    "        else:\n",
    "            tempkernel = (1,5)\n",
    "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
    "                            {'filter': 256, 'kernel': tempkernel, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
    "        \n",
    "    skip_36 = x\n",
    "        \n",
    "    # Layer 37 => 40\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "\n",
    "    # Layer 41 => 61\n",
    "    for i in range(7):\n",
    "        if i % 2 == 0:\n",
    "            tempkernel = (5,1)\n",
    "        else:\n",
    "            tempkernel = (1,5)\n",
    "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
    "                            {'filter': 512, 'kernel': tempkernel, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
    "        \n",
    "    skip_61 = x\n",
    "        \n",
    "    # Layer 62 => 65\n",
    "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "                        {'filter': 1024, 'kernel': (1,5), 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "\n",
    "    # Layer 66 => 74\n",
    "    for i in range(3):\n",
    "        if i % 2 == 0:\n",
    "            tempkernel = (5,1)\n",
    "        else:\n",
    "            tempkernel = (1,5)\n",
    "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
    "                            {'filter': 1024, 'kernel': tempkernel, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
    "        \n",
    "    # Layer 75 => 79\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "                        {'filter': 1024, 'kernel': (1,5), 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "                        {'filter': 1024, 'kernel': (5,1), 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
    "\n",
    "    # Layer 80 => 82\n",
    "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
    "                              {'filter':  3*(5 + CLASS), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
    "\n",
    "    # Layer 83 => 86\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_61])\n",
    "\n",
    "    # Layer 87 => 91\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "                        {'filter': 512, 'kernel': (1,5), 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "                        {'filter': 512, 'kernel': (5,1), 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
    "\n",
    "    # Layer 92 => 94\n",
    "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
    "                              {'filter': 3*(5 + CLASS), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
    "\n",
    "    # Layer 95 => 98\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_36])\n",
    "\n",
    "    # Layer 99 => 106\n",
    "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
    "                               {'filter': 256, 'kernel': (1,5), 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
    "                               {'filter': 256, 'kernel': (5,1), 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
    "                               {'filter': 3*(5 + CLASS), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
    "    yolo_82 =  Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(yolo_82)\n",
    "    yolo_94 =  Reshape((GRID_H*2, GRID_W*2, BOX, 4 + 1 + CLASS))(yolo_94)\n",
    "    yolo_106 =  Reshape((GRID_H*4, GRID_W*4, BOX, 4 + 1 + CLASS))(yolo_106)\n",
    "\n",
    "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = make_yolov3_model()\n",
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major,    = struct.unpack('i', w_f.read(4))\n",
    "            minor,    = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "\n",
    "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                w_f.read(4)\n",
    "\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "            \n",
    "            binary = w_f.read()\n",
    "\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "        \n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "    def load_weights(self, model):\n",
    "        for i in range(106):\n",
    "            if i  in [81, 93, 105]:\n",
    "                continue\n",
    "            try:\n",
    "                conv_layer = model.get_layer('conv_' + str(i))\n",
    "                if conv_layer.kernel.shape[0] == conv_layer.kernel.shape[1] :\n",
    "                    print(\"loading weights of convolution #\" + str(i))\n",
    "\n",
    "                    if i not in [81, 93, 105]:\n",
    "                        norm_layer = model.get_layer('bnorm_' + str(i))\n",
    "\n",
    "                        size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "                        beta  = self.read_bytes(size) # bias\n",
    "                        gamma = self.read_bytes(size) # scale\n",
    "                        mean  = self.read_bytes(size) # mean\n",
    "                        var   = self.read_bytes(size) # variance            \n",
    "\n",
    "                        weights = norm_layer.set_weights([gamma, beta, mean, var])  \n",
    "\n",
    "                    if len(conv_layer.get_weights()) > 1:\n",
    "                        bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "                        kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "\n",
    "                        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                        kernel = kernel.transpose([2,3,1,0])\n",
    "                        conv_layer.set_weights([kernel, bias])\n",
    "                    else:\n",
    "                        kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                        kernel = kernel.transpose([2,3,1,0])\n",
    "                        conv_layer.set_weights([kernel])\n",
    "            except ValueError:\n",
    "                print(\"no convolution #\" + str(i))     \n",
    "    \n",
    "    def reset(self):\n",
    "        self.offset = 0\n",
    "weight_reader = WeightReader(weights_path)\n",
    "weight_reader.load_weights(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_yolov3_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('current_best2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights(\"weights_coconew.h5\")\n",
    "\n",
    "def single_loss(anchor_index):\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        # only caculate the y_true[...,4] > -0.5\n",
    "        \n",
    "        caculate_index = y_true[...,4] + 2\n",
    "        true_box_conf = tf.clip_by_value(y_true[...,4],0,1)\n",
    "        #GRID_W , GRID_H = mask_shape[1], mask_shape[2]\n",
    "        scale_anchor = 2**anchor_index\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Adjust prediction\n",
    "        \"\"\"\n",
    "        ### adjust x and y    \n",
    "        \n",
    "        pred_box_xy = tf.sigmoid(y_pred[..., :2])\n",
    "        ### adjust w and h\n",
    "        pred_box_wh = tf.exp(y_pred[..., 2:4])*np.reshape(ANCHORS[anchor_index], [1,1,1,BOX,2])\n",
    "                              \n",
    "\n",
    "        ### adjust confidence\n",
    "        pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "                              \n",
    "\n",
    "        ### adjust class probabilities\n",
    "        #pred_box_class = y_pred[..., 5:]\n",
    "        pred_box_class = tf.sigmoid(y_pred[..., 5:] )\n",
    "                              \n",
    "\n",
    "        \"\"\"\n",
    "        Adjust ground truth\n",
    "        \"\"\"\n",
    "        ### adjust x and y\n",
    "        center_xy = y_true[..., :2] \n",
    "        true_box_xy = center_xy# - tf.floor(center_xy)# relative position to the containing cell\n",
    "                              \n",
    "\n",
    "        ### adjust w and h\n",
    "        true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "                              \n",
    "        ### adjust confidence\n",
    "\n",
    "        #true_box_conf = iou_scores * y_true[..., 4]\n",
    "\n",
    "        ### adjust class probabilities\n",
    "        true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "                              \n",
    "        true_box_classfy = y_true[..., 5:]\n",
    "\n",
    "        \"\"\"\n",
    "        Determine the masks\n",
    "        \"\"\"\n",
    "        ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "        coord_mask = true_box_conf#y_true[..., 4]#tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "\n",
    "        ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "\n",
    "        # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "        #conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE + (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "\n",
    "        #conf_mask = true_box_conf * OBJECT_SCALE + (1 - true_box_conf) * NO_OBJECT_SCALE\n",
    "        ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "        class_mask = true_box_conf * CLASS_SCALE       \n",
    "\n",
    "        \"\"\"\n",
    "        Warm-up training\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "                              \n",
    "\n",
    "        \"\"\"\n",
    "        Finalize the loss\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        # 按置信系数给长框设置权重\n",
    "        maxconf = tf.reduce_max(pred_box_conf, axis = 3 ,keepdims=True) - 0.1\n",
    "        \n",
    "        loss_conf = tf.nn.relu(pred_box_conf - maxconf)#+ tf.to_float(pred_box_conf > maxconf - 1e-4)*1e-6\n",
    "        whscale = loss_conf/tf.reduce_sum(loss_conf,axis = 3,keepdims=True ) \n",
    "        whscale = tf.expand_dims(whscale, 4)\n",
    "        pred_box_wh = tf.reduce_sum(pred_box_wh*whscale, axis = 3,keepdims=True)\n",
    "        pred_box_xy = tf.reduce_sum(pred_box_xy*whscale, axis = 3,keepdims=True)\n",
    "        \n",
    "        # 更改了这两个所属的位置\n",
    "                           \n",
    "        caculate_index = caculate_index + 0.2*tf.reduce_max(caculate_index,axis=[1,2,3], keepdims=True)*pred_box_conf*tf.to_float(y_true[...,4] > - 0.5)\n",
    "        caculate_index_num = tf.reduce_sum(caculate_index) + 1e-6    \n",
    "        \n",
    "        \n",
    "        scalewh  =    tf.to_float(true_box_wh > 1e-6)/( true_box_wh + 1e-6)\n",
    "        loss_xy    = tf.reduce_sum(tf.nn.relu(tf.abs(true_box_xy-pred_box_xy)*scalewh*2 - 0.1), axis=-1 ) * coord_mask#/ (nb_coord_box + 1e-6) / 2.\n",
    "        loss_wh    = tf.reduce_sum(tf.nn.relu(tf.abs(true_box_wh - pred_box_wh)*scalewh - 0.1), axis=-1 )  * coord_mask#/ (nb_coord_box + 1e-6) / 2.\n",
    "     \n",
    "        #loss_xy    = tf.reduce_sum(tf.nn.relu(tf.abs(true_box_xy-pred_box_xy) - tf.clip_by_value(0.02*true_box_wh , 0.01,1)), axis=-1 ) * coord_mask#/ (nb_coord_box + 1e-6) / 2.\n",
    "        #loss_wh    = tf.reduce_sum(tf.nn.relu(tf.abs(tf.sqrt(true_box_wh)-tf.sqrt(pred_box_wh)) - 0.1), axis=-1 )  * coord_mask#/ (nb_coord_box + 1e-6) / 2.\n",
    "        loss_conf  = tf.nn.relu(tf.abs(tf.reduce_sum(true_box_conf,axis=3,keepdims=True) - tf.reduce_sum(pred_box_conf,axis=3,keepdims=True)) - 0.3) *caculate_index#  / (nb_conf_box  + 1e-6) / 2.\n",
    "        \n",
    "        # 非目标领域误检的加大惩罚系数\n",
    "        loss_class = tf.reduce_sum(tf.nn.relu(tf.abs(true_box_classfy - pred_box_class) - 0.1 ), axis=-1 )*class_mask\n",
    "        \n",
    "        coord_mask_num =  tf.reduce_sum(coord_mask) + 1e-6\n",
    "        class_mask_num = tf.reduce_sum(class_mask) + 1e-6\n",
    "        \n",
    "        loss = (loss_xy + loss_wh  + loss_class)/coord_mask_num + loss_conf/caculate_index_num\n",
    "        \n",
    "        loss = tf.reduce_sum(loss)\n",
    "        \n",
    "        '''\n",
    "        loss_xy = tf.reduce_sum(loss_xy)/coord_mask_num \n",
    "        loss_wh = tf.reduce_sum(loss_wh)/coord_mask_num \n",
    "        loss_conf = tf.reduce_sum(loss_conf)/caculate_index_num\n",
    "        loss_class = tf.reduce_sum(loss_class)/class_mask_num\n",
    "        loss = loss_xy + loss_wh + loss_conf + loss_class# + loss_coor_conf\n",
    "        '''\n",
    "\n",
    "        return loss\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    'IMAGE_H'         : IMAGE_H, \n",
    "    'IMAGE_W'         : IMAGE_W,\n",
    "    'GRID_H'          : GRID_H,  \n",
    "    'GRID_W'          : GRID_W,\n",
    "    'BOX'             : BOX,\n",
    "    'LABELS'          : LABELS,\n",
    "    'CLASS'           : len(LABELS),\n",
    "    'ANCHORS'         : ANCHORS,\n",
    "    'BATCH_SIZE'      : BATCH_SIZE,\n",
    "    'TRUE_BOX_BUFFER' : 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return image / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from preprocessing import parse_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_imgs = parse_annotation(train_annot_folder, train_image_folder, labels=LABELS)\n",
    "#valid_imgs, seen_train_labels = parse_annotation(valid_annot_folder, train_image_folder, labels=LABELS)\n",
    "valid_imgs = train_imgs[::2]\n",
    "#train_imgs = train_imgs[1::2]\n",
    "\n",
    "train_batch = BatchGenerator(train_imgs, generator_config, norm=normalize)\n",
    "valid_batch = BatchGenerator(valid_imgs, generator_config, norm=normalize, jitter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=0.001, \n",
    "                           patience=3, \n",
    "                           mode='min', \n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('yolov3_18.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min', \n",
    "                             period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 139s 1s/step - loss: 0.0631 - reshape_1_loss: 0.0173 - reshape_2_loss: 0.0346 - reshape_3_loss: 0.0112 - val_loss: 0.0627 - val_reshape_1_loss: 0.0118 - val_reshape_2_loss: 0.0304 - val_reshape_3_loss: 0.0205\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06268, saving model to yolov3_18.h5\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 118s 1s/step - loss: 0.0747 - reshape_1_loss: 0.0192 - reshape_2_loss: 0.0444 - reshape_3_loss: 0.0111 - val_loss: 0.0520 - val_reshape_1_loss: 0.0120 - val_reshape_2_loss: 0.0296 - val_reshape_3_loss: 0.0105\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06268 to 0.05204, saving model to yolov3_18.h5\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 115s 1s/step - loss: 0.0684 - reshape_1_loss: 0.0140 - reshape_2_loss: 0.0453 - reshape_3_loss: 0.0091 - val_loss: 0.0601 - val_reshape_1_loss: 0.0165 - val_reshape_2_loss: 0.0271 - val_reshape_3_loss: 0.0165\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05204\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 115s 1s/step - loss: 0.1061 - reshape_1_loss: 0.0466 - reshape_2_loss: 0.0456 - reshape_3_loss: 0.0139 - val_loss: 0.0503 - val_reshape_1_loss: 0.0152 - val_reshape_2_loss: 0.0256 - val_reshape_3_loss: 0.0095\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05204 to 0.05030, saving model to yolov3_18.h5\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 115s 1s/step - loss: 0.0672 - reshape_1_loss: 0.0107 - reshape_2_loss: 0.0452 - reshape_3_loss: 0.0113 - val_loss: 0.0422 - val_reshape_1_loss: 0.0115 - val_reshape_2_loss: 0.0231 - val_reshape_3_loss: 0.0076\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05030 to 0.04224, saving model to yolov3_18.h5\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 120s 1s/step - loss: 0.0645 - reshape_1_loss: 0.0104 - reshape_2_loss: 0.0423 - reshape_3_loss: 0.0118 - val_loss: 0.0450 - val_reshape_1_loss: 0.0125 - val_reshape_2_loss: 0.0228 - val_reshape_3_loss: 0.0097\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04224\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 114s 1s/step - loss: 0.0651 - reshape_1_loss: 0.0149 - reshape_2_loss: 0.0391 - reshape_3_loss: 0.0111 - val_loss: 0.0672 - val_reshape_1_loss: 0.0125 - val_reshape_2_loss: 0.0313 - val_reshape_3_loss: 0.0233\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04224\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 113s 1s/step - loss: 0.0612 - reshape_1_loss: 0.0118 - reshape_2_loss: 0.0385 - reshape_3_loss: 0.0108 - val_loss: 0.0622 - val_reshape_1_loss: 0.0115 - val_reshape_2_loss: 0.0412 - val_reshape_3_loss: 0.0094\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04224\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0,clipvalue=1)\n",
    "\n",
    "model.compile(loss=[single_loss(0),single_loss(1), single_loss(2)], optimizer=optimizer)\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    history = model.fit_generator(generator        = train_batch, \n",
    "                    steps_per_epoch  = len(train_batch), \n",
    "                    epochs           = 100, \n",
    "                    verbose          = 1,\n",
    "                    validation_data  = valid_batch,\n",
    "                    validation_steps = len(valid_batch),\n",
    "                    callbacks        = [checkpoint,early_stop], \n",
    "                    max_queue_size   = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:0\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 184s 920ms/step - loss: 0.0691 - reshape_1_loss: 0.0129 - reshape_2_loss: 0.0415 - reshape_3_loss: 0.0147 - val_loss: 0.0762 - val_reshape_1_loss: 0.0227 - val_reshape_2_loss: 0.0304 - val_reshape_3_loss: 0.0231\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.04224\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 184s 920ms/step - loss: 0.0713 - reshape_1_loss: 0.0259 - reshape_2_loss: 0.0354 - reshape_3_loss: 0.0100 - val_loss: 0.0801 - val_reshape_1_loss: 0.0258 - val_reshape_2_loss: 0.0331 - val_reshape_3_loss: 0.0213\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04224\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 184s 919ms/step - loss: 0.0577 - reshape_1_loss: 0.0154 - reshape_2_loss: 0.0311 - reshape_3_loss: 0.0112 - val_loss: 0.0446 - val_reshape_1_loss: 0.0129 - val_reshape_2_loss: 0.0197 - val_reshape_3_loss: 0.0120\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04224\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 185s 926ms/step - loss: 0.0621 - reshape_1_loss: 0.0141 - reshape_2_loss: 0.0366 - reshape_3_loss: 0.0113 - val_loss: 0.0480 - val_reshape_1_loss: 0.0158 - val_reshape_2_loss: 0.0232 - val_reshape_3_loss: 0.0089\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04224\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 185s 923ms/step - loss: 0.0648 - reshape_1_loss: 0.0200 - reshape_2_loss: 0.0321 - reshape_3_loss: 0.0127 - val_loss: 0.0771 - val_reshape_1_loss: 0.0161 - val_reshape_2_loss: 0.0336 - val_reshape_3_loss: 0.0275\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.04224\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 184s 921ms/step - loss: 0.0683 - reshape_1_loss: 0.0191 - reshape_2_loss: 0.0383 - reshape_3_loss: 0.0109 - val_loss: 0.0943 - val_reshape_1_loss: 0.0182 - val_reshape_2_loss: 0.0436 - val_reshape_3_loss: 0.0325\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04224\n",
      "Epoch 00006: early stopping\n",
      "Iteration:1\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 184s 919ms/step - loss: 0.0644 - reshape_1_loss: 0.0189 - reshape_2_loss: 0.0323 - reshape_3_loss: 0.0132 - val_loss: 0.0529 - val_reshape_1_loss: 0.0125 - val_reshape_2_loss: 0.0283 - val_reshape_3_loss: 0.0120\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.04224\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 184s 919ms/step - loss: 0.0677 - reshape_1_loss: 0.0221 - reshape_2_loss: 0.0340 - reshape_3_loss: 0.0116 - val_loss: 0.0768 - val_reshape_1_loss: 0.0217 - val_reshape_2_loss: 0.0324 - val_reshape_3_loss: 0.0226\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.04224\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 190s 948ms/step - loss: 0.0692 - reshape_1_loss: 0.0206 - reshape_2_loss: 0.0372 - reshape_3_loss: 0.0115 - val_loss: 0.0661 - val_reshape_1_loss: 0.0155 - val_reshape_2_loss: 0.0299 - val_reshape_3_loss: 0.0208\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.04224\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 186s 928ms/step - loss: 0.0704 - reshape_1_loss: 0.0128 - reshape_2_loss: 0.0462 - reshape_3_loss: 0.0114 - val_loss: 0.0545 - val_reshape_1_loss: 0.0185 - val_reshape_2_loss: 0.0246 - val_reshape_3_loss: 0.0115\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04224\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(\"Iteration:{}\".format(i))\n",
    "\n",
    "    model.fit_generator(generator        = train_batch, \n",
    "                    steps_per_epoch  = len(train_batch), \n",
    "                    epochs           = 100, \n",
    "                    verbose          = 1,\n",
    "                    validation_data  = valid_batch,\n",
    "                    validation_steps = len(valid_batch),\n",
    "                    callbacks        = [early_stop, checkpoint], \n",
    "                    max_queue_size   = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('yolov3_18.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image_folder = '/home/zhuleike/data/science/Test/JPEGImages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-721934838178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#filename = 'utils.py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#exec(compile(open(filename, \"rb\").read(), filename, 'exec'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcurrent_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_batch' is not defined"
     ]
    }
   ],
   "source": [
    "#from utils import decode_netout2\n",
    "#filename = 'utils.py'\n",
    "#exec(compile(open(filename, \"rb\").read(), filename, 'exec'))\n",
    "current_test = train_batch\n",
    "\n",
    "for number in range(20):\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    imagepath = current_test[number]['filename']\n",
    "    objects = current_test[number]['object']\n",
    "\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    image = cv2.imread(imagepath)\n",
    "    h, w, c = image.shape\n",
    "  \n",
    "    input_image = cv2.resize(image, (IMAGE_W, IMAGE_H))\n",
    "    input_image = input_image / 255.\n",
    "    input_image = input_image[:,:,::-1]\n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "    netout = model.predict(input_image)\n",
    "    boxes = decode_netout(netout, \n",
    "                          obj_threshold=OBJ_THRESHOLD,\n",
    "                          nms_threshold=NMS_THRESHOLD,\n",
    "                          anchors=ANCHORS, \n",
    "                          nb_class=CLASS)    \n",
    "    fontsize = 3\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2,new_probs  = box.xmin, box.ymin, box.xmax, box.ymax, box.c\n",
    "        key = LABELS[box.get_label()]\n",
    "        xmin, ymin, xmax, ymax = int(x1*w),int(y1*h), int(x2*w), int(y2*h)\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255,0,0), 2)\n",
    "        (retval,baseLine) = cv2.getTextSize(key,1,1,1)\n",
    "        cv2.rectangle(image, (xmin - fontsize *5 , ymin+baseLine*fontsize -15), (xmin , ymin-retval[1]*fontsize  - 15), (0, 0, 0), 3)\n",
    "        cv2.rectangle(image, (xmin - fontsize *5,ymin+baseLine*fontsize  -15), (xmin+retval[0]*fontsize , ymin -retval[1]*fontsize  - 15), (0, 225, 0), -1)\n",
    "        cv2.putText(image, key, (xmin  , ymin - 10), fontsize , 1, (0, 0, 225), 3)   \n",
    "\n",
    "        \n",
    "    for obj in objects:\n",
    "        xmin, ymin, xmax, ymax =  obj['xmin'],obj['ymin'],obj['xmax'],obj['ymax']\n",
    "        cv2.rectangle(image, (obj['xmin'],obj['ymin']), (obj['xmax'],obj['ymax']), (0,255,0), 2)\n",
    "        (retval,baseLine) = cv2.getTextSize(obj['name'],1,1,1)\n",
    "        cv2.rectangle(image, (xmax - fontsize *5 , ymin+baseLine*fontsize -15), (xmax , ymin-retval[1]*fontsize  - 15), (0, 0, 0), 3)\n",
    "        cv2.rectangle(image, (xmax - fontsize *5,ymin+baseLine*fontsize  -15), (xmax+retval[0]*fontsize , ymin -retval[1]*fontsize  - 15), (0, 0, 255), -1)\n",
    "        cv2.putText(image, obj['name'], (xmax  , ymin - 10), fontsize , 1, (0, 255, 0), 3)   \n",
    "\n",
    "    plt.imshow(image); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'preprocessing.py'\n",
    "exec(compile(open(filename, \"rb\").read(), filename, 'exec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagehw = []\n",
    "mistake = []\n",
    "for img in all_imgs:\n",
    "    txtfilename = '/home/zhuleike/data/science/Train/gt_formula/gt_' + img['filename'].split('/')[-1][:-4] + '.txt'\n",
    "    fo = open(txtfilename,\"w\")\n",
    "    \n",
    "    for obj in img['object']:     \n",
    "        if obj['name'] == 'formulaRegion':\n",
    "            x1,x2,y1,y2 = obj['xmin'], obj['xmax'], obj['ymin'], obj['ymax'],\n",
    "            coord = str(x1)+','+str(y1)+','+str(x2)+','+str(y1)+','+ str(x2)+','+str(y2)+','+ str(x1)+','+str(y2)+',formulaRegion'\n",
    "            fo.write(coord + '\\n')\n",
    "    fo.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # 构建卷积神经网络结构\n",
    "    input_image = Input(shape = (32, 960,3))\n",
    "    x = Conv2D(32, (3, 3), strides=(1,1), use_bias =False)(input_image)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 4))(x)\n",
    "    x = Conv2D(64, (3, 3), strides=(1,1), use_bias =False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 4))(x)\n",
    "    for i in range(0,3):\n",
    "        channel = min(512, 128*(2**i))\n",
    "        x = Conv2D(channel*2, (1, 1), use_bias =False, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)        \n",
    "        x = Conv2D(channel, (2, 4), strides=(1,1), use_bias =False, padding='valid')(x) \n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "        \n",
    "    x = Conv2D(channel, (2, 4), strides=(1,1), use_bias =False, name = 'end1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = Conv2D(128, (2, 1), strides=(1,1), use_bias =False, name = 'end2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)    \n",
    "    x = Conv2D(2, (1, 1), use_bias =False,activation='sigmoid', name = 'endl3')(x)\n",
    "\n",
    "    model = Model(inputs=input_image, outputs=x)\n",
    "    return model\n",
    "\n",
    "#formula_model = build_model()\n",
    "formula_model = build_model()\n",
    "formula_model.load_weights('/home/zhuleike/workspace/bishe/muticlassfy/rotatnew.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import decode_netout2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def build_model():\n",
    "    # 构建卷积神经网络结构\n",
    "    input_image = Input(shape = (32, 960,3))\n",
    "    x = Conv2D(32, (3, 3), strides=(2,2), use_bias =False)(input_image)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), strides=(1,1), use_bias =False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    for i in range(0,4):\n",
    "        channel = min(512, 128*(2**i))\n",
    "        x = Conv2D(channel, (1, 3), strides=(1,2), use_bias =False, padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "        x = Conv2D(channel, (2, 2), strides=(1,1), use_bias =False, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "    x =  Conv2D(channel, (2, 3), strides=(2,2), use_bias =False, name = 'end1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = Conv2D(128, (1, 2), strides=(1,1), use_bias =False, name = 'end2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)    \n",
    "    x = Conv2D(2, (1, 1), use_bias =False,activation='sigmoid', name = 'endl3')(x)\n",
    "\n",
    "    model = Model(inputs=input_image, outputs=x)\n",
    "    return model\n",
    "#formula_model = build_model()\n",
    "formula_model = build_model()\n",
    "formula_model.load_weights('/home/zhuleike/workspace/bishe/muticlassfy/rotatemore.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def judge_image_col(image):\n",
    "    h,w,_ = image.shape\n",
    "    image = image[h//4: h//4*3]\n",
    "    a = np.sum(np.max(image)-image, 0)\n",
    "    a = np.max(a,-1)\n",
    "    lena = len(a)\n",
    "    down = int(450.0/1100*lena)\n",
    "    uppe = int(600.0/1100*lena)\n",
    "\n",
    "    middle = np.where(a[down:uppe] < np.mean(a)*0.1)[0]\n",
    "\n",
    "    if len(middle) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(np.mean(middle)+down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.31713557243347\n"
     ]
    }
   ],
   "source": [
    "filename = 'utils.py'\n",
    "exec(compile(open(filename, \"rb\").read(), filename, 'exec'))\n",
    "import time\n",
    "import xml\n",
    "OBJ_THRESHOLD    = 0.11\n",
    "NMS_THRESHOLD    = 0.4\n",
    "start_time = time.time()\n",
    "doc = xml.dom.minidom.Document() \n",
    "#在内存中创建一个空的文档\n",
    "offyy = 5\n",
    "root = doc.createElement('root') \n",
    "def writeimage(imagename):\n",
    "    singleimage = doc.createElement('document') \n",
    "    singleimage.setAttribute('filename', imagename) \n",
    "    return singleimage  \n",
    "# generate the probs and coords for boxes\n",
    "def write2xml(boxname,  prob, coord):\n",
    "\n",
    "\n",
    "    nodeManager = doc.createElement(boxname)\n",
    "    nodeManager.setAttribute('prob', prob)\n",
    "    nodeName = doc.createElement('Coords')\n",
    "    nodeName.setAttribute('points', coord)\n",
    "\n",
    "    nodeManager.appendChild(nodeName)\n",
    "    return nodeManager\n",
    "\n",
    "for idx, img_name in enumerate(sorted(os.listdir(test_image_folder))):\n",
    "    if not img_name.lower().endswith(('.bmp', '.jpeg', '.jpg', '.png', '.tif', '.tiff')):\n",
    "        continue\n",
    "    singleimage = writeimage(img_name)\n",
    "    imagepath = os.path.join(test_image_folder,img_name)\n",
    "\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    image = cv2.imread(imagepath)\n",
    "    col_index = judge_image_col(image)\n",
    "    if col_index!= 0:\n",
    "        image_l = image[:,:col_index]/255.0\n",
    "        image_r = image[:,col_index:]/255.0\n",
    "    h,w,_ = image.shape\n",
    "    \n",
    "    \n",
    "    input_image = cv2.resize(image, (IMAGE_H, IMAGE_W))\n",
    "    input_image = input_image / 255.\n",
    "    input_image = input_image[:,:,::-1]\n",
    "\n",
    "    \n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "    netout = model.predict(input_image)\n",
    "    boxes = decode_netout2(netout, \n",
    "                          obj_threshold=OBJ_THRESHOLD,\n",
    "                          nms_threshold=NMS_THRESHOLD,\n",
    "                          anchors=ANCHORS, \n",
    "                          nb_class=CLASS)    \n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2,new_probs  = box.xmin, box.ymin, box.xmax, box.ymax, box.c\n",
    "        \n",
    "        key = LABELS[box.get_label()]\n",
    "        x1, y1, x2, y2 = int(round(x1*w)), int(round(y1*h)), int(round(x2*w)), int(round(y2*h))        \n",
    "        if x1 < 10 or y1 < 10 or x2> w-10 or y2 > h - 10 or x2 - x1 < 10 or y2 - y1 < 10:\n",
    "            continue         \n",
    "        \n",
    "        if key == LABELS[-1] and new_probs < 0.90:\n",
    "            if col_index == 0:\n",
    "                tempimage = np.copy(image)/255.0\n",
    "                xx1 = x1\n",
    "                xx2 = x2\n",
    "            elif x2<= col_index:\n",
    "                tempimage = np.copy(image_l)\n",
    "                xx1 = x1\n",
    "                xx2 = x2               \n",
    "                \n",
    "            elif x1 >= col_index:\n",
    "                tempimage = np.copy(image_r)\n",
    "                xx1 = x1 - col_index\n",
    "                xx2 = x2 - col_index\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            temp = tempimage[y1-offyy:y2+offyy]\n",
    "            temp[offyy:-offyy,xx1:xx2,-1] = 0\n",
    "            temp = cv2.resize(temp, (960, 32))\n",
    "            temp = np.clip(temp, 0,1)\n",
    "            temp2 = np.expand_dims(temp, 0)\n",
    "            temp2 = formula_model.predict(temp2)\n",
    "            if temp2[0,0,0,1] > 0.9:\n",
    "                #plt.imshow(temp);plt.show()\n",
    "                continue                   \n",
    "            \n",
    "        coord = str(x1)+','+str(y1)+' '+str(x2)+','+str(y1)+' '+ str(x1)+','+str(y2)+' '+ str(x2)+','+str(y2)\n",
    "        \n",
    "        nodeManager = write2xml( key, str(new_probs), coord)\n",
    "        singleimage.appendChild(nodeManager)\n",
    " \n",
    "    root.appendChild(singleimage)\n",
    "\n",
    "doc.appendChild(root)\n",
    "fp = open('Manager.xml', 'w')\n",
    "doc.writexml(fp, indent='\\t', addindent='\\t', newl='\\n', encoding=\"utf-8\")\n",
    "print(time.time() - start_time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAAuCAYAAAA4AeJ2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model.save_weights('current_best2.h5')\n",
    "plt.imshow(temp);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('current_best2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.480872631073\n"
     ]
    }
   ],
   "source": [
    "filename = 'utils.py'\n",
    "exec(compile(open(filename, \"rb\").read(), filename, 'exec'))\n",
    "import time\n",
    "import xml\n",
    "OBJ_THRESHOLD    = 0.11\n",
    "NMS_THRESHOLD    = 0.4\n",
    "start_time = time.time()\n",
    "doc = xml.dom.minidom.Document() \n",
    "#在内存中创建一个空的文档\n",
    "offyy = 5\n",
    "root = doc.createElement('root') \n",
    "def writeimage(imagename):\n",
    "    singleimage = doc.createElement('document') \n",
    "    singleimage.setAttribute('filename', imagename) \n",
    "    return singleimage  \n",
    "# generate the probs and coords for boxes\n",
    "def write2xml(boxname,  prob, coord):\n",
    "\n",
    "\n",
    "    nodeManager = doc.createElement(boxname)\n",
    "    nodeManager.setAttribute('prob', prob)\n",
    "    nodeName = doc.createElement('Coords')\n",
    "    nodeName.setAttribute('points', coord)\n",
    "\n",
    "    nodeManager.appendChild(nodeName)\n",
    "    return nodeManager\n",
    "\n",
    "for idx, img_name in enumerate(sorted(os.listdir(test_image_folder))):\n",
    "    if not img_name.lower().endswith(('.bmp', '.jpeg', '.jpg', '.png', '.tif', '.tiff')):\n",
    "        continue\n",
    "    singleimage = writeimage(img_name)\n",
    "    imagepath = os.path.join(test_image_folder,img_name)\n",
    "\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    image = cv2.imread(imagepath)\n",
    "    col_index = judge_image_col(image)\n",
    "    if col_index!= 0:\n",
    "        image_l = image[:,:col_index]/255.0\n",
    "        image_r = image[:,col_index:]/255.0\n",
    "    h,w,_ = image.shape\n",
    "    \n",
    "    \n",
    "    input_image = cv2.resize(image, (IMAGE_H, IMAGE_W))\n",
    "    input_image = input_image / 255.\n",
    "    input_image = input_image[:,:,::-1]\n",
    "\n",
    "    \n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "    netout = model.predict(input_image)\n",
    "    boxes = decode_netout2(netout, \n",
    "                          obj_threshold=OBJ_THRESHOLD,\n",
    "                          nms_threshold=NMS_THRESHOLD,\n",
    "                          anchors=ANCHORS, \n",
    "                          nb_class=CLASS)    \n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2,new_probs  = box.xmin, box.ymin, box.xmax, box.ymax, box.c\n",
    "        \n",
    "        key = LABELS[box.get_label()]\n",
    "        x1, y1, x2, y2 = int(round(x1*w)), int(round(y1*h)), int(round(x2*w)), int(round(y2*h))        \n",
    "        if x1 < 10 or y1 < 10 or x2> w-10 or y2 > h - 10 or x2 - x1 < 10 or y2 - y1 < 10:\n",
    "            continue         \n",
    "                \n",
    "            \n",
    "        coord = str(x1)+','+str(y1)+' '+str(x2)+','+str(y1)+' '+ str(x1)+','+str(y2)+' '+ str(x2)+','+str(y2)\n",
    "        \n",
    "        nodeManager = write2xml( key, str(new_probs), coord)\n",
    "        singleimage.appendChild(nodeManager)\n",
    " \n",
    "    root.appendChild(singleimage)\n",
    "\n",
    "doc.appendChild(root)\n",
    "fp = open('Manager.xml', 'w')\n",
    "doc.writexml(fp, indent='\\t', addindent='\\t', newl='\\n', encoding=\"utf-8\")\n",
    "print(time.time() - start_time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
