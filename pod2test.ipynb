{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分布类别不检测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "import struct\n",
    "import xml.dom.minidom\n",
    "\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers import LeakyReLU,AvgPool2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint#, TensorBoard\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.merge import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "config = K.tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = K.tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "from tqdm import tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, cv2\n",
    "from preprocessing import parse_annotation, BatchGenerator\n",
    "from utils import WeightReader, decode_netout2, draw_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ANCHORS  = [[0.36,0.17,  0.67,0.24, 0.18,0.105], [0.65,0.16, 0.197,0.06, 0.39,0.076],[0.18,0.02, 0.35,0.026, 0.56,0.03]]\n",
    "\n",
    "LABELS = ['tableRegion', 'figureRegion', 'formulaRegion']\n",
    "GRID_H,  GRID_W  = 15 , 15\n",
    "IMAGE_H, IMAGE_W = GRID_H*64,  GRID_W*64\n",
    "\n",
    "\n",
    "ANCHORS = np.asarray(ANCHORS,dtype=np.float32)*np.asarray([[GRID_H], [GRID_H*2], [GRID_H*4]])\n",
    "BOX              = 3\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.6#0.5\n",
    "NMS_THRESHOLD    = 0.3#0.45\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_path = 'yolov3.weights'                      \n",
    "train_image_folder = '/home/zhuleike/data/science/Train/JPEGImages/'\n",
    "train_annot_folder = '/home/zhuleike/data/science/Train/Annotations/'\n",
    "test_image_folder = '/home/zhuleike/data/science/Test/JPEGImages/'\n",
    "test_annot_folder = '/home/zhuleike/data/science/Test/annotations/'\n",
    "#valid_annot_folder = '/home/trunk/RTrunk0/zhuleike/data/VOCdevkit/VOC2012/Annotations/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        \n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "        \n",
    "        return self.label\n",
    "    \n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "            \n",
    "        return self.score\n",
    "\n",
    "def _conv_block(inp, convs, skip=True):\n",
    "    x = inp\n",
    "    count = 0\n",
    "    i = 0\n",
    "    for conv in convs:\n",
    "        if count == (len(convs) - 2) and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "        \n",
    "\n",
    "        x = Conv2D(conv['filter'], \n",
    "                   kernel_size = conv['kernel'], \n",
    "                   strides=conv['stride'], \n",
    "                   padding='same', \n",
    "                   name='conv_' + str(conv['layer_idx']), \n",
    "                   use_bias=False if conv['bnorm'] else True)(x)\n",
    "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "\n",
    "    return add([skip_connection, x]) if skip else x\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3          \n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    \n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    \n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union\n",
    "\n",
    "def make_yolov3_model():\n",
    "    input_image = Input(shape=(None, None, 3))\n",
    "\n",
    "    # Layer  0 => 4\n",
    "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "\n",
    "    # Layer  5 => 8\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "\n",
    "    # Layer  9 => 11\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "\n",
    "    # Layer 12 => 15\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "\n",
    "    # Layer 16 => 36\n",
    "    \n",
    "    for i in range(7):\n",
    "        if i % 2 == 0:\n",
    "            tempkernel = (5,1)\n",
    "        else:\n",
    "            tempkernel = (1,5)\n",
    "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
    "                            {'filter': 256, 'kernel': tempkernel, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
    "        \n",
    "    skip_36 = x\n",
    "        \n",
    "    # Layer 37 => 40\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "\n",
    "    # Layer 41 => 61\n",
    "    for i in range(7):\n",
    "        if i % 2 == 0:\n",
    "            tempkernel = (5,1)\n",
    "        else:\n",
    "            tempkernel = (1,5)\n",
    "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
    "                            {'filter': 512, 'kernel': tempkernel, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
    "        \n",
    "    skip_61 = x\n",
    "        \n",
    "    # Layer 62 => 65\n",
    "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "                        {'filter': 1024, 'kernel': (1,5), 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "\n",
    "    # Layer 66 => 74\n",
    "    for i in range(3):\n",
    "        if i % 2 == 0:\n",
    "            tempkernel = (5,1)\n",
    "        else:\n",
    "            tempkernel = (1,5)\n",
    "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
    "                            {'filter': 1024, 'kernel': tempkernel, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
    "        \n",
    "    # Layer 75 => 79\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "                        {'filter': 1024, 'kernel': (1,5), 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "                        {'filter': 1024, 'kernel': (5,1), 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
    "\n",
    "    # Layer 80 => 82\n",
    "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
    "                              {'filter':  3*(5 + CLASS), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
    "\n",
    "    # Layer 83 => 86\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_61])\n",
    "\n",
    "    # Layer 87 => 91\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "                        {'filter': 512, 'kernel': (1,5), 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "                        {'filter': 512, 'kernel': (5,1), 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
    "\n",
    "    # Layer 92 => 94\n",
    "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
    "                              {'filter': 3*(5 + CLASS), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
    "\n",
    "    # Layer 95 => 98\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_36])\n",
    "\n",
    "    # Layer 99 => 106\n",
    "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
    "                               {'filter': 256, 'kernel': (1,5), 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
    "                               {'filter': 256, 'kernel': (5,1), 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
    "                               {'filter': 3*(5 + CLASS), 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
    "    yolo_82 =  Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(yolo_82)\n",
    "    yolo_94 =  Reshape((GRID_H*2, GRID_W*2, BOX, 4 + 1 + CLASS))(yolo_94)\n",
    "    yolo_106 =  Reshape((GRID_H*4, GRID_W*4, BOX, 4 + 1 + CLASS))(yolo_106)\n",
    "\n",
    "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_yolov3_model()\n",
    "#model.load_weights('current_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('yolov3_18.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('current_best2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('weights_coco_yolov3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    'IMAGE_H'         : IMAGE_H, \n",
    "    'IMAGE_W'         : IMAGE_W,\n",
    "    'GRID_H'          : GRID_H,  \n",
    "    'GRID_W'          : GRID_W,\n",
    "    'BOX'             : BOX,\n",
    "    'LABELS'          : LABELS,\n",
    "    'CLASS'           : len(LABELS),\n",
    "    'ANCHORS'         : ANCHORS,\n",
    "    'BATCH_SIZE'      : BATCH_SIZE,\n",
    "    'TRUE_BOX_BUFFER' : 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return image / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from preprocessing import parse_annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_imgs = parse_annotation(train_annot_folder, train_image_folder, labels=LABELS)\n",
    "#valid_imgs, seen_train_labels = parse_annotation(valid_annot_folder, train_image_folder, labels=LABELS)\n",
    "#valid_imgs = train_imgs[::2]\n",
    "\n",
    "#train_batch = BatchGenerator(train_imgs, generator_config, norm=normalize)\n",
    "#valid_batch = BatchGenerator(valid_imgs, generator_config, norm=normalize, jitter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_imgs = parse_annotation(test_annot_folder, test_image_folder, labels=LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('best_pod22.h5')\n",
    "#all_imgs = parse_annotation(train_annot_folder, train_image_folder, labels=LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # 构建卷积神经网络结构\n",
    "    input_image = Input(shape = (32, 960,3))\n",
    "    x = Conv2D(32, (3, 3), strides=(1,1), use_bias =False)(input_image)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 4))(x)\n",
    "    x = Conv2D(64, (3, 3), strides=(1,1), use_bias =False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 4))(x)\n",
    "    for i in range(0,3):\n",
    "        channel = min(512, 128*(2**i))\n",
    "        x = Conv2D(channel*2, (1, 1), use_bias =False, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)        \n",
    "        x = Conv2D(channel, (2, 4), strides=(1,1), use_bias =False, padding='valid')(x) \n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "        \n",
    "    x = Conv2D(channel, (2, 4), strides=(1,1), use_bias =False, name = 'end1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = Conv2D(128, (2, 1), strides=(1,1), use_bias =False, name = 'end2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)    \n",
    "    x = Conv2D(2, (1, 1), use_bias =False,activation='sigmoid', name = 'endl3')(x)\n",
    "\n",
    "    model = Model(inputs=input_image, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def judge_image_col(image):\n",
    "    h,w,_ = image.shape\n",
    "    image2 = image[h//4: h//4*3]\n",
    "    a = np.sum(np.max(image2)-image2, 0)\n",
    "    a = np.max(a,-1)\n",
    "    lena = len(a)\n",
    "    down = int(450.0/1100*lena)\n",
    "    uppe = int(600.0/1100*lena)\n",
    "\n",
    "    middle = np.where(a[down:uppe] < np.mean(a)*0.1)[0]\n",
    "\n",
    "    if len(middle) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(np.mean(middle)+down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'utils.py'\n",
    "exec(compile(open(filename, \"rb\").read(), filename, 'exec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula_model = build_model()\n",
    "formula_model.load_weights('/home/zhuleike/workspace/bishe/muticlassfy/rotatnew.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.29244375228882\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "OBJ_THRESHOLD    = 0.2\n",
    "NMS_THRESHOLD    = 0.4\n",
    "start_time = time.time()\n",
    "doc = xml.dom.minidom.Document() \n",
    "#在内存中创建一个空的文档\n",
    "\n",
    "root = doc.createElement('root') \n",
    "def writeimage(imagename):\n",
    "    singleimage = doc.createElement('document') \n",
    "    singleimage.setAttribute('filename', imagename) \n",
    "    return singleimage  \n",
    "# generate the probs and coords for boxes\n",
    "def write2xml(boxname,  prob, coord):\n",
    "\n",
    "\n",
    "    nodeManager = doc.createElement(boxname)\n",
    "    nodeManager.setAttribute('prob', prob)\n",
    "    nodeName = doc.createElement('Coords')\n",
    "    nodeName.setAttribute('points', coord)\n",
    "\n",
    "    nodeManager.appendChild(nodeName)\n",
    "    return nodeManager\n",
    "\n",
    "for idx, img_name in enumerate(sorted(os.listdir(test_image_folder))):\n",
    "    if not img_name.lower().endswith(('.bmp', '.jpeg', '.jpg', '.png', '.tif', '.tiff')):\n",
    "        continue\n",
    "    singleimage = writeimage(img_name)\n",
    "    imagepath = os.path.join(test_image_folder,img_name)\n",
    "\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    image = cv2.imread(imagepath)\n",
    "    col_index = judge_image_col(image)\n",
    "    if col_index!= 0:\n",
    "        image_l = image[:,:col_index]/250.0\n",
    "        image_r = image[:,col_index:]/250.0\n",
    "    h,w,_ = image.shape\n",
    "    \n",
    "    \n",
    "    input_image = cv2.resize(image, (IMAGE_H, IMAGE_W))\n",
    "    input_image = input_image / 255.\n",
    "    input_image = input_image[:,:,::-1]\n",
    "\n",
    "    \n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "    netout = model.predict(input_image)\n",
    "    boxes = decode_netout2(netout, \n",
    "                          obj_threshold=OBJ_THRESHOLD,\n",
    "                          nms_threshold=NMS_THRESHOLD,\n",
    "                          anchors=ANCHORS, \n",
    "                          nb_class=CLASS)    \n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2,new_probs  = box.xmin, box.ymin, box.xmax, box.ymax, box.c\n",
    "        \n",
    "        key = LABELS[box.get_label()]\n",
    "        x1, y1, x2, y2 = int(round(x1*w)), int(round(y1*h)), int(round(x2*w)), int(round(y2*h))        \n",
    "        if x1 < 10 or y1 < 10 or x2> w-10 or y2 > h - 10:\n",
    "            continue         \n",
    "         \n",
    "        if key == LABELS[-1] and new_probs < 0.90:\n",
    "            if col_index == 0:\n",
    "                tempimage = image/250.0\n",
    "                xx1 = x1\n",
    "                xx2 = x2\n",
    "            elif x2<= col_index:\n",
    "                tempimage = np.copy(image_l)\n",
    "                xx1 = x1\n",
    "                xx2 = x2               \n",
    "                \n",
    "            elif x1 >= col_index:\n",
    "                tempimage = np.copy(image_r)\n",
    "                xx1 = x1 - col_index\n",
    "                xx2 = x2 - col_index\n",
    "                \n",
    "            temp = tempimage[y1-2:y2+2]\n",
    "            temp[:,xx1:xx2,-1] = 0\n",
    "            temp = cv2.resize(temp, (960, 32))\n",
    "            temp = np.clip(temp, 0,1)\n",
    "            temp2 = np.expand_dims(temp, 0)\n",
    "            temp2 = formula_model.predict(temp2)\n",
    "            if temp2[0,0,0,1] > 0.9:\n",
    "                continue\n",
    "                        \n",
    "            \n",
    "        coord = str(x1)+','+str(y1)+' '+str(x2)+','+str(y1)+' '+ str(x1)+','+str(y2)+' '+ str(x2)+','+str(y2)\n",
    "        \n",
    "        nodeManager = write2xml( key, str(new_probs), coord)\n",
    "        singleimage.appendChild(nodeManager)\n",
    " \n",
    "    root.appendChild(singleimage)\n",
    "\n",
    "doc.appendChild(root)\n",
    "fp = open('Manager.xml', 'w')\n",
    "doc.writexml(fp, indent='\\t', addindent='\\t', newl='\\n', encoding=\"utf-8\")\n",
    "print(time.time() - start_time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "978"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2\n",
    "#np.where(np.mean(tempimage[middley,:col_index[1]],axis=-1) < 0.1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJ_THRESHOLD    = 0.2\n",
    "NMS_THRESHOLD    = 0.4\n",
    "import xml.dom.minidom\n",
    "doc = xml.dom.minidom.Document() \n",
    "#在内存中创建一个空的文档\n",
    "root = doc.createElement('root') \n",
    "def writeimage(imagename):\n",
    "    singleimage = doc.createElement('document') \n",
    "    singleimage.setAttribute('filename', imagename) \n",
    "    return singleimage  \n",
    "# generate the probs and coords for boxes\n",
    "def write2xml(boxname,  prob, coord):\n",
    "\n",
    "\n",
    "    nodeManager = doc.createElement(boxname)\n",
    "    nodeManager.setAttribute('prob', prob)\n",
    "    nodeName = doc.createElement('Coords')\n",
    "    nodeName.setAttribute('points', coord)\n",
    "\n",
    "    nodeManager.appendChild(nodeName)\n",
    "    return nodeManager\n",
    "\n",
    "for idx, img_name in enumerate(sorted(os.listdir(test_image_folder))):\n",
    "    if not img_name.lower().endswith(('.bmp', '.jpeg', '.jpg', '.png', '.tif', '.tiff')):\n",
    "        continue\n",
    "    singleimage = writeimage(img_name)\n",
    "    imagepath = os.path.join(test_image_folder,img_name)\n",
    "\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    image = cv2.imread(imagepath)\n",
    "    h,w,_ = image.shape\n",
    "    \n",
    "    input_image = cv2.resize(image, (IMAGE_H, IMAGE_W))\n",
    "    input_image = input_image / 255.\n",
    "    input_image = input_image[:,:,::-1]\n",
    "\n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "    netout = model.predict(input_image)\n",
    "    boxes = decode_netout2(netout, \n",
    "                          obj_threshold=OBJ_THRESHOLD,\n",
    "                          nms_threshold=NMS_THRESHOLD,\n",
    "                          anchors=ANCHORS, \n",
    "                          nb_class=CLASS)    \n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2,new_probs  = box.xmin, box.ymin, box.xmax, box.ymax, box.c\n",
    "        \n",
    "        key = LABELS[box.get_label()]\n",
    "        x1, y1, x2, y2 = int(round(x1*w)), int(round(y1*h)), int(round(x2*w)), int(round(y2*h))        \n",
    "\n",
    "        if x1 < 10 or y1 < 10 or x2> w-10 or y2 > h - 10:\n",
    "            continue  \n",
    "        coord = str(x1)+','+str(y1)+' '+str(x2)+','+str(y1)+' '+ str(x1)+','+str(y2)+' '+ str(x2)+','+str(y2)\n",
    "        \n",
    "        nodeManager = write2xml( key, str(new_probs), coord)\n",
    "        singleimage.appendChild(nodeManager)\n",
    "        \n",
    "    root.appendChild(singleimage)\n",
    "\n",
    "doc.appendChild(root)\n",
    "fp = open('Manager.xml', 'w')\n",
    "doc.writexml(fp, indent='\\t', addindent='\\t', newl='\\n', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'utils.py'\n",
    "exec(compile(open(filename, \"rb\").read(), filename, 'exec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1//8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "65.74"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
